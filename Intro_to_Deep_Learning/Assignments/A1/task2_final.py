# -*- coding: utf-8 -*-
"""task2_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bvAoUK-Ge5AHF3VV4-2sL4bAQWZ4tJQ0

# Task 2

## Imports
"""

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard
# %tensorboard --logdir=./my_logs --port=6006
import numpy as np
import os
import time
import tensorflow as tf
from tensorflow import keras
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

"""## Data Preparation and Setup"""

seed = 8032
keras.utils.set_random_seed(seed)

data = np.load("./a2_data/images.npy")
labels = np.load("./a2_data/labels.npy")

X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2)
X_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, test_size=0.5)

X_train = X_train.astype("float32")
X_valid = X_valid.astype("float32")
X_test = X_test.astype("float32")

X_train /= 255
X_valid /= 255
X_test /= 255

print(labels.shape)
print(X_train.shape)
print(X_valid.shape)
print(X_test.shape)

def log_root():
    root_logdir = os.path.join(os.curdir, "my_logs")
    run_id = time.strftime("run_%Y_%m_%d-%H_%M_%S")
    return os.path.join(root_logdir, run_id)

y_test_regression = y_test[:,0] + y_test[:, 1] / 60

def common_sense_error(y_true, y_pred):
    return np.array([min(abs(y_true[i] - y_pred[i]), abs(abs(y_true[i] - y_pred[i]) - 6)) for i in range(y_true.shape[0])])

histories = [] #create a list to store the histories of all networks
classifier_models = []
regressor_models = []
mulhead_models = []
labtrans_models = []
nb_classifiers = 9
nb_regressors = 3
nb_mulhead = 4
nb_labtrans = 2
model_names = {
    0:"classifier_c2_h2_lr01",
    1:"classifier_c2_h2_lr005",
    2:"classifier_c2_h2_lr001",
    3:"classifier_c2_h3_lr01",
    4:"classifier_c2_h3_lr005",
    5:"classifier_c2_h3_lr001",
    6:"classifier_c3_h3_lr01",
    7:"classifier_c3_h3_lr005",
    8:"classifier_c3_h3_lr001",
    9:"regressor_c2_h2_lr001_s1",
    10:"regressor_c2_h3_lr001_s2",
    11:"regressor_c2_h4_lr001_s3",
    12:"hc_mr",
    13:"hc_mc",
    14:"hr_mr",
    15:"hr_mc",
    16:"sincos_4heads",
    17:"sincos_2heads"
}

"""## 2.1

### Classifier
"""

keras.utils.set_random_seed(seed)

"""#### 2 Convolution Patterns and 2 Hidden Layers

##### Learning rate 0.1
"""

y_test_classifier = 60 * y_test[:, 0] + y_test[:, 1]
y_valid_classifier = 60 * y_valid[:, 0] + y_valid[:, 1]
y_train_classifier = 60 * y_train[:, 0] + y_train[:, 1] # adapt the labels to match the output of our model

classifier_input_ = keras.layers.Input(shape=(X_train.shape[1], X_train.shape[2], 1))
classifier_conv1 = keras.layers.Conv2D(32, (3,3), activation="relu", padding="same")(classifier_input_)
classifier_conv2 = keras.layers.Conv2D(32, (3,3), activation="relu", padding="same")(classifier_conv1)
classifier_pool1 = keras.layers.MaxPooling2D((2,2))(classifier_conv2)
classifier_conv3 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same")(classifier_pool1)
classifier_conv4 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same")(classifier_conv3)
classifier_pool2 = keras.layers.MaxPooling2D((2,2))(classifier_conv4)
classifier_flatten = keras.layers.Flatten()(classifier_pool2)

classifier_dense1 = keras.layers.Dense(512, activation="relu")(classifier_flatten)
classifier_dropout4 = keras.layers.Dropout(0.25)(classifier_dense1)
classifier_dense2 = keras.layers.Dense(512, activation="relu")(classifier_dropout4)
classifier_dropout5 = keras.layers.Dropout(0.25)(classifier_dense2)
classifier_out = keras.layers.Dense(720, activation="softmax")(classifier_dropout5)
classifier_model = keras.Model(inputs=[classifier_input_], outputs=[classifier_out])

tensorboard_cb = keras.callbacks.TensorBoard(log_root())
classifier_model.compile(loss=keras.losses.SparseCategoricalCrossentropy(), optimizer=keras.optimizers.SGD(learning_rate=0.1),
                         metrics=["accuracy"])
classifier_model.summary()

histories.append(classifier_model.fit(X_train, y_train_classifier, epochs=150, validation_data=(X_valid, y_valid_classifier), callbacks=[tensorboard_cb], batch_size=256))
classifier_models.append(classifier_model)

classifier_model.save("classifier_c2_h2_lr01.keras")

"""##### Learning rate 0.05"""

classifier_input_ = keras.layers.Input(shape=(X_train.shape[1], X_train.shape[2], 1))
classifier_conv1 = keras.layers.Conv2D(32, (3,3), activation="relu", padding="same")(classifier_input_)
classifier_conv2 = keras.layers.Conv2D(32, (3,3), activation="relu", padding="same")(classifier_conv1)
classifier_pool1 = keras.layers.MaxPooling2D((2,2))(classifier_conv2)
classifier_conv3 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same")(classifier_pool1)
classifier_conv4 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same")(classifier_conv3)
classifier_pool2 = keras.layers.MaxPooling2D((2,2))(classifier_conv4)
classifier_flatten = keras.layers.Flatten()(classifier_pool2)

classifier_dense1 = keras.layers.Dense(512, activation="relu")(classifier_flatten)
classifier_dropout4 = keras.layers.Dropout(0.25)(classifier_dense1)
classifier_dense2 = keras.layers.Dense(512, activation="relu")(classifier_dropout4)
classifier_dropout5 = keras.layers.Dropout(0.25)(classifier_dense2)
classifier_out = keras.layers.Dense(720, activation="softmax")(classifier_dropout5)
classifier_model = keras.Model(inputs=[classifier_input_], outputs=[classifier_out])

tensorboard_cb = keras.callbacks.TensorBoard(log_root())
classifier_model.compile(loss=keras.losses.SparseCategoricalCrossentropy(), optimizer=keras.optimizers.SGD(learning_rate=0.05),
                         metrics=["accuracy"])
classifier_model.summary()

histories.append(classifier_model.fit(X_train, y_train_classifier, epochs=150, validation_data=(X_valid, y_valid_classifier), callbacks=[tensorboard_cb], batch_size=128))
classifier_models.append(classifier_model)

classifier_model.save("classifier_c2_h2_lr005.keras")

"""##### Learning rate 0.01"""

classifier_input_ = keras.layers.Input(shape=(X_train.shape[1], X_train.shape[2], 1))
classifier_conv1 = keras.layers.Conv2D(32, (3,3), activation="relu", padding="same")(classifier_input_)
classifier_conv2 = keras.layers.Conv2D(32, (3,3), activation="relu", padding="same")(classifier_conv1)
classifier_pool1 = keras.layers.MaxPooling2D((2,2))(classifier_conv2)
classifier_conv3 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same")(classifier_pool1)
classifier_conv4 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same")(classifier_conv3)
classifier_pool2 = keras.layers.MaxPooling2D((2,2))(classifier_conv4)
classifier_flatten = keras.layers.Flatten()(classifier_pool2)

classifier_dense1 = keras.layers.Dense(512, activation="relu")(classifier_flatten)
classifier_dropout4 = keras.layers.Dropout(0.25)(classifier_dense1)
classifier_dense2 = keras.layers.Dense(512, activation="relu")(classifier_dropout4)
classifier_dropout5 = keras.layers.Dropout(0.25)(classifier_dense2)
classifier_out = keras.layers.Dense(720, activation="softmax")(classifier_dropout5)
classifier_model = keras.Model(inputs=[classifier_input_], outputs=[classifier_out])

tensorboard_cb = keras.callbacks.TensorBoard(log_root())
classifier_model.compile(loss=keras.losses.SparseCategoricalCrossentropy(), optimizer=keras.optimizers.SGD(learning_rate=0.1),
                         metrics=["accuracy"])
classifier_model.summary()

histories.append(classifier_model.fit(X_train, y_train_classifier, epochs=150, validation_data=(X_valid, y_valid_classifier), callbacks=[tensorboard_cb], batch_size=64))
classifier_models.append(classifier_model)

classifier_model.save("classifier_c2_h2_lr001.keras")

"""#### 2 Convolution Patterns and 3 Hidden Layers

##### Learning rate 0.1
"""

classifier_input_ = keras.layers.Input(shape=(X_train.shape[1], X_train.shape[2], 1))
classifier_conv1 = keras.layers.Conv2D(32, (3,3), activation="relu", padding="same")(classifier_input_)
classifier_conv2 = keras.layers.Conv2D(32, (3,3), activation="relu", padding="same")(classifier_conv1)
classifier_pool1 = keras.layers.MaxPooling2D((2,2))(classifier_conv2)
classifier_conv3 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same")(classifier_pool1)
classifier_conv4 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same")(classifier_conv3)
classifier_pool2 = keras.layers.MaxPooling2D((2,2))(classifier_conv4)
classifier_flatten = keras.layers.Flatten()(classifier_pool2)

classifier_dense1 = keras.layers.Dense(512, activation="relu")(classifier_flatten)
classifier_dropout4 = keras.layers.Dropout(0.25)(classifier_dense1)
classifier_dense2 = keras.layers.Dense(512, activation="relu")(classifier_dropout4)
classifier_dropout5 = keras.layers.Dropout(0.25)(classifier_dense2)
classifier_dense3 = keras.layers.Dense(512, activation="relu")(classifier_dropout5)
classifier_dropout6 = keras.layers.Dropout(0.25)(classifier_dense3)
classifier_out = keras.layers.Dense(720, activation="softmax")(classifier_dropout6)
classifier_model = keras.Model(inputs=[classifier_input_], outputs=[classifier_out])

tensorboard_cb = keras.callbacks.TensorBoard(log_root())
classifier_model.compile(loss=keras.losses.SparseCategoricalCrossentropy(), optimizer=keras.optimizers.SGD(learning_rate=0.1),
                         metrics=["accuracy"])
classifier_model.summary()

histories.append(classifier_model.fit(X_train, y_train_classifier, epochs=150, validation_data=(X_valid, y_valid_classifier), callbacks=[tensorboard_cb], batch_size=256))
classifier_models.append(classifier_model)

classifier_model.save("classifier_c2_h3_lr01.keras")

"""##### Learning rate 0.05"""

classifier_input_ = keras.layers.Input(shape=(X_train.shape[1], X_train.shape[2], 1))
classifier_conv1 = keras.layers.Conv2D(32, (3,3), activation="relu", padding="same")(classifier_input_)
classifier_conv2 = keras.layers.Conv2D(32, (3,3), activation="relu", padding="same")(classifier_conv1)
classifier_pool1 = keras.layers.MaxPooling2D((2,2))(classifier_conv2)
classifier_conv3 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same")(classifier_pool1)
classifier_conv4 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same")(classifier_conv3)
classifier_pool2 = keras.layers.MaxPooling2D((2,2))(classifier_conv4)
classifier_flatten = keras.layers.Flatten()(classifier_pool2)

classifier_dense1 = keras.layers.Dense(512, activation="relu")(classifier_flatten)
classifier_dropout4 = keras.layers.Dropout(0.25)(classifier_dense1)
classifier_dense2 = keras.layers.Dense(512, activation="relu")(classifier_dropout4)
classifier_dropout5 = keras.layers.Dropout(0.25)(classifier_dense2)
classifier_dense3 = keras.layers.Dense(512, activation="relu")(classifier_dropout5)
classifier_dropout6 = keras.layers.Dropout(0.25)(classifier_dense3)
classifier_out = keras.layers.Dense(720, activation="softmax")(classifier_dropout6)
classifier_model = keras.Model(inputs=[classifier_input_], outputs=[classifier_out])

tensorboard_cb = keras.callbacks.TensorBoard(log_root())
classifier_model.compile(loss=keras.losses.SparseCategoricalCrossentropy(), optimizer=keras.optimizers.SGD(learning_rate=0.05),
                         metrics=["accuracy"])
classifier_model.summary()

histories.append(classifier_model.fit(X_train, y_train_classifier, epochs=150, validation_data=(X_valid, y_valid_classifier), callbacks=[tensorboard_cb], batch_size=128))
classifier_models.append(classifier_model)

classifier_model.save("classifier_c2_h3_lr005.keras")

"""##### Learning rate 0.01"""

classifier_input_ = keras.layers.Input(shape=(X_train.shape[1], X_train.shape[2], 1))
classifier_conv1 = keras.layers.Conv2D(32, (3,3), activation="relu", padding="same")(classifier_input_)
classifier_conv2 = keras.layers.Conv2D(32, (3,3), activation="relu", padding="same")(classifier_conv1)
classifier_pool1 = keras.layers.MaxPooling2D((2,2))(classifier_conv2)
classifier_conv3 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same")(classifier_pool1)
classifier_conv4 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same")(classifier_conv3)
classifier_pool2 = keras.layers.MaxPooling2D((2,2))(classifier_conv4)
classifier_conv5 = keras.layers.Conv2D(128, (3,3), activation="relu", padding="same")(classifier_pool2)
classifier_conv6 = keras.layers.Conv2D(128, (3,3), activation="relu", padding="same")(classifier_conv5)
classifier_pool3 = keras.layers.MaxPooling2D((2,2))(classifier_conv6)
classifier_flatten = keras.layers.Flatten()(classifier_pool3)

classifier_dense1 = keras.layers.Dense(512, activation="relu")(classifier_flatten)
classifier_dropout4 = keras.layers.Dropout(0.25)(classifier_dense1)
classifier_dense2 = keras.layers.Dense(512, activation="relu")(classifier_dropout4)
classifier_dropout5 = keras.layers.Dropout(0.25)(classifier_dense2)
classifier_dense3 = keras.layers.Dense(512, activation="relu")(classifier_dropout5)
classifier_dropout6 = keras.layers.Dropout(0.25)(classifier_dense3)
classifier_out = keras.layers.Dense(720, activation="softmax")(classifier_dropout6)
classifier_model = keras.Model(inputs=[classifier_input_], outputs=[classifier_out])

tensorboard_cb = keras.callbacks.TensorBoard(log_root())
classifier_model.compile(loss=keras.losses.SparseCategoricalCrossentropy(), optimizer=keras.optimizers.SGD(learning_rate=0.1),
                         metrics=["accuracy"])
classifier_model.summary()

histories.append(classifier_model.fit(X_train, y_train_classifier, epochs=150, validation_data=(X_valid, y_valid_classifier), callbacks=[tensorboard_cb], batch_size=64))
classifier_models.append(classifier_model)

classifier_model.save("classifier_c2_h3_lr001.keras")

"""#### 3 Convolution Patterns and 3 Hidden Layers

##### Learning rate 0.1
"""

classifier_input_ = keras.layers.Input(shape=(X_train.shape[1], X_train.shape[2], 1))
classifier_conv1 = keras.layers.Conv2D(32, (3,3), activation="relu", padding="same")(classifier_input_)
classifier_conv2 = keras.layers.Conv2D(32, (3,3), activation="relu", padding="same")(classifier_conv1)
classifier_pool1 = keras.layers.MaxPooling2D((2,2))(classifier_conv2)
classifier_conv3 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same")(classifier_pool1)
classifier_conv4 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same")(classifier_conv3)
classifier_pool2 = keras.layers.MaxPooling2D((2,2))(classifier_conv4)
classifier_conv5 = keras.layers.Conv2D(128, (3,3), activation="relu", padding="same")(classifier_pool2)
classifier_conv6 = keras.layers.Conv2D(128, (3,3), activation="relu", padding="same")(classifier_conv5)
classifier_pool3 = keras.layers.MaxPooling2D((2,2))(classifier_conv6)
classifier_flatten = keras.layers.Flatten()(classifier_pool3)

classifier_dense1 = keras.layers.Dense(512, activation="relu")(classifier_flatten)
classifier_dropout4 = keras.layers.Dropout(0.25)(classifier_dense1)
classifier_dense2 = keras.layers.Dense(512, activation="relu")(classifier_dropout4)
classifier_dropout5 = keras.layers.Dropout(0.25)(classifier_dense2)
classifier_dense3 = keras.layers.Dense(512, activation="relu")(classifier_dropout5)
classifier_dropout6 = keras.layers.Dropout(0.25)(classifier_dense3)
classifier_out = keras.layers.Dense(720, activation="softmax")(classifier_dropout6)
classifier_model = keras.Model(inputs=[classifier_input_], outputs=[classifier_out])

tensorboard_cb = keras.callbacks.TensorBoard(log_root())
classifier_model.compile(loss=keras.losses.SparseCategoricalCrossentropy(), optimizer=keras.optimizers.SGD(learning_rate=0.1),
                         metrics=["accuracy"])
classifier_model.summary()

histories.append(classifier_model.fit(X_train, y_train_classifier, epochs=150, validation_data=(X_valid, y_valid_classifier), callbacks=[tensorboard_cb], batch_size=256))
classifier_models.append(classifier_model)

classifier_model.save("classifier_c3_h3_lr01.keras")

"""##### Learning rate 0.05"""

classifier_input_ = keras.layers.Input(shape=(X_train.shape[1], X_train.shape[2], 1))
classifier_conv1 = keras.layers.Conv2D(32, (3,3), activation="relu", padding="same")(classifier_input_)
classifier_conv2 = keras.layers.Conv2D(32, (3,3), activation="relu", padding="same")(classifier_conv1)
classifier_pool1 = keras.layers.MaxPooling2D((2,2))(classifier_conv2)
classifier_conv3 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same")(classifier_pool1)
classifier_conv4 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same")(classifier_conv3)
classifier_pool2 = keras.layers.MaxPooling2D((2,2))(classifier_conv4)
classifier_conv5 = keras.layers.Conv2D(128, (3,3), activation="relu", padding="same")(classifier_pool2)
classifier_conv6 = keras.layers.Conv2D(128, (3,3), activation="relu", padding="same")(classifier_conv5)
classifier_pool3 = keras.layers.MaxPooling2D((2,2))(classifier_conv6)
classifier_flatten = keras.layers.Flatten()(classifier_pool3)

classifier_dense1 = keras.layers.Dense(512, activation="relu")(classifier_flatten)
classifier_dropout4 = keras.layers.Dropout(0.25)(classifier_dense1)
classifier_dense2 = keras.layers.Dense(512, activation="relu")(classifier_dropout4)
classifier_dropout5 = keras.layers.Dropout(0.25)(classifier_dense2)
classifier_dense3 = keras.layers.Dense(512, activation="relu")(classifier_dropout5)
classifier_dropout6 = keras.layers.Dropout(0.25)(classifier_dense3)
classifier_out = keras.layers.Dense(720, activation="softmax")(classifier_dropout6)
classifier_model = keras.Model(inputs=[classifier_input_], outputs=[classifier_out])

tensorboard_cb = keras.callbacks.TensorBoard(log_root())
classifier_model.compile(loss=keras.losses.SparseCategoricalCrossentropy(), optimizer=keras.optimizers.SGD(learning_rate=0.05),
                         metrics=["accuracy"])
classifier_model.summary()

histories.append(classifier_model.fit(X_train, y_train_classifier, epochs=150, validation_data=(X_valid, y_valid_classifier), callbacks=[tensorboard_cb], batch_size=128))
classifier_models.append(classifier_model)

classifier_model.save("classifier_c3_h3_lr005.keras")

"""##### Learning rate 0.01"""

classifier_input_ = keras.layers.Input(shape=(X_train.shape[1], X_train.shape[2], 1))
classifier_conv1 = keras.layers.Conv2D(32, (3,3), activation="relu", padding="same")(classifier_input_)
classifier_conv2 = keras.layers.Conv2D(32, (3,3), activation="relu", padding="same")(classifier_conv1)
classifier_pool1 = keras.layers.MaxPooling2D((2,2))(classifier_conv2)
classifier_conv3 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same")(classifier_pool1)
classifier_conv4 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same")(classifier_conv3)
classifier_pool2 = keras.layers.MaxPooling2D((2,2))(classifier_conv4)
classifier_conv5 = keras.layers.Conv2D(128, (3,3), activation="relu", padding="same")(classifier_pool2)
classifier_conv6 = keras.layers.Conv2D(128, (3,3), activation="relu", padding="same")(classifier_conv5)
classifier_pool3 = keras.layers.MaxPooling2D((2,2))(classifier_conv6)
classifier_flatten = keras.layers.Flatten()(classifier_pool3)

classifier_dense1 = keras.layers.Dense(512, activation="relu")(classifier_flatten)
classifier_dropout4 = keras.layers.Dropout(0.25)(classifier_dense1)
classifier_dense2 = keras.layers.Dense(512, activation="relu")(classifier_dropout4)
classifier_dropout5 = keras.layers.Dropout(0.25)(classifier_dense2)
classifier_dense3 = keras.layers.Dense(512, activation="relu")(classifier_dropout5)
classifier_dropout6 = keras.layers.Dropout(0.25)(classifier_dense3)
classifier_out = keras.layers.Dense(720, activation="softmax")(classifier_dropout6)
classifier_model = keras.Model(inputs=[classifier_input_], outputs=[classifier_out])

tensorboard_cb = keras.callbacks.TensorBoard(log_root())
classifier_model.compile(loss=keras.losses.SparseCategoricalCrossentropy(), optimizer=keras.optimizers.SGD(learning_rate=0.1),
                         metrics=["accuracy"])
classifier_model.summary()

histories.append(classifier_model.fit(X_train, y_train_classifier, epochs=150, validation_data=(X_valid, y_valid_classifier), callbacks=[tensorboard_cb], batch_size=64))
classifier_models.append(classifier_model)

classifier_model.save("classifier_c3_h3_lr001.keras")

"""#### Classifier Results"""

plt.figure(figsize=(12,4))
plt.subplot(1,2,1)
for i in range(nb_classifiers):
    plt.plot(histories[i].history["loss"])
plt.ylabel('loss')
plt.xlabel('epoch')
plt.title('Model Training Loss')
plt.legend([model_names[x].replace("classifier_", "") for x in range(nb_classifiers)], loc='upper center', bbox_to_anchor=(1.2, 1))

plt.subplot(1,2,2)
for i in range(nb_classifiers):
    plt.plot(histories[i].history["val_loss"])
plt.ylabel('validation loss')
plt.xlabel('epoch')
plt.title('Model Validation Loss')
plt.legend([model_names[x].replace("classifier_", "") for x in range(nb_classifiers)], loc='upper center', bbox_to_anchor=(1.2, 1))
plt.subplots_adjust(wspace=0.55)

plt.figure(figsize=(12,4))
plt.subplot(1,2,1)
for i in range(nb_classifiers):
    plt.plot(histories[i].history["accuracy"])
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.title('Model Training Accuracy')
plt.legend([model_names[x].replace("classifier_", "") for x in range(nb_classifiers)], loc='upper center', bbox_to_anchor=(1.2, 1))

plt.subplot(1,2,2)
for i in range(nb_classifiers):
    plt.plot(histories[i].history["val_accuracy"])
plt.ylabel('validation accuracy')
plt.xlabel('epoch')
plt.title('Model Validation Accuracy')
plt.legend([model_names[x].replace("classifier_", "") for x in range(nb_classifiers)], loc='upper center', bbox_to_anchor=(1.2, 1))
plt.subplots_adjust(wspace=0.55)

for i in range(nb_classifiers):
    classifier_model = classifier_models[i]
    classifier_outs = classifier_model.predict_on_batch(X_test)
    classifier_scaled_outs = classifier_outs[:, 0] +  classifier_outs[:, 1] / 60
    classifier_mean_common_sense_error = np.mean(common_sense_error(y_test_regression, classifier_scaled_outs))
    name = model_names[i].split("_")
    print(f'The mean common sense error of the classification model with {name[1][1:]} convolution patterns, {name[2][1:]} hidden layers and 0.{name[3][3:]} learning rate is {classifier_mean_common_sense_error // 1} hours and {classifier_mean_common_sense_error % 1 * 60} minutes.')

"""### Regression"""

keras.utils.set_random_seed(seed)

"""#### Stride 1"""

y_test_regression = y_test[:,0] + y_test[:, 1] / 60
y_valid_regression = y_valid[:,0] + y_valid[:, 1] / 60
y_train_regression = y_train[:,0] + y_train[:, 1] / 60 # adapt the labels to match the output of our model

regression_input_ = keras.layers.Input(shape=(X_train.shape[1], X_train.shape[2], 1))
regression_conv1 = keras.layers.Conv2D(32, (3,3), activation="relu", padding="same")(regression_input_)
regression_conv2 = keras.layers.Conv2D(32, (3,3), activation="relu", padding="same")(regression_conv1)
regression_pool1 = keras.layers.MaxPooling2D((2,2))(regression_conv2)
regression_dropout1 = keras.layers.Dropout(0.25)(regression_pool1)
regression_conv3 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same")(regression_dropout1)
regression_conv4 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same")(regression_conv3)
regression_pool2 = keras.layers.MaxPooling2D((2,2))(regression_conv4)
regression_dropout2 = keras.layers.Dropout(0.25)(regression_pool2)
regression_flatten = keras.layers.Flatten()(regression_dropout2)

regression_dense1 = keras.layers.Dense(256, activation="relu")(regression_flatten)
regression_dropout3 = keras.layers.Dropout(0.25)(regression_dense1)
regression_dense2 = keras.layers.Dense(256, activation="relu")(regression_dropout3)
regression_dropout4 = keras.layers.Dropout(0.25)(regression_dense2)
regression_dense3 = keras.layers.Dense(256, activation="relu")(regression_dropout4)
regression_dropout5 = keras.layers.Dropout(0.25)(regression_dense3)
regression_out = keras.layers.Dense(1, activation="relu")(regression_dropout5)

regression_model = keras.Model(inputs=[regression_input_], outputs=[regression_out])

tensorboard_cb = keras.callbacks.TensorBoard(log_root())
regression_model.compile(loss="mse", optimizer=keras.optimizers.SGD(0.1),
                         metrics=["mean_absolute_error"])
regression_model.summary()

histories.append(regression_model.fit(X_train, y_train_regression, epochs=150, validation_data=(X_valid, y_valid_regression), callbacks=[tensorboard_cb]))
regressor_models.append(regression_model)

regression_model.save("regressor_c2_h2_lr001_s1.keras")

"""#### Stride 2"""

regression_input_ = keras.layers.Input(shape=(X_train.shape[1], X_train.shape[2], 1))
regression_conv1 = keras.layers.Conv2D(32, (3,3), activation="relu", padding="same", strides=(2, 2))(regression_input_)
regression_conv2 = keras.layers.Conv2D(32, (3,3), activation="relu", padding="same", strides=(2, 2))(regression_conv1)
regression_pool1 = keras.layers.MaxPooling2D((2,2))(regression_conv2)
regression_dropout1 = keras.layers.Dropout(0.25)(regression_pool1)
regression_conv3 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same", strides=(2, 2))(regression_dropout1)
regression_conv4 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same", strides=(2, 2))(regression_conv3)
regression_pool2 = keras.layers.MaxPooling2D((2,2))(regression_conv4)
regression_dropout2 = keras.layers.Dropout(0.25)(regression_pool2)
regression_flatten = keras.layers.Flatten()(regression_dropout2)

regression_dense1 = keras.layers.Dense(256, activation="relu")(regression_flatten)
regression_dropout3 = keras.layers.Dropout(0.25)(regression_dense1)
regression_dense2 = keras.layers.Dense(256, activation="relu")(regression_dropout3)
regression_dropout4 = keras.layers.Dropout(0.25)(regression_dense2)
regression_dense3 = keras.layers.Dense(256, activation="relu")(regression_dropout4)
regression_dropout5 = keras.layers.Dropout(0.25)(regression_dense3)
regression_out = keras.layers.Dense(1, activation="relu")(regression_dropout5)

regression_model = keras.Model(inputs=[regression_input_], outputs=[regression_out])

tensorboard_cb = keras.callbacks.TensorBoard(log_root())
regression_model.compile(loss="mse", optimizer=keras.optimizers.SGD(),
                         metrics=["mean_absolute_error"])
regression_model.summary()

histories.append(regression_model.fit(X_train, y_train_regression, epochs=150, validation_data=(X_valid, y_valid_regression), callbacks=[tensorboard_cb]))
regressor_models.append(regression_model)

regression_model.save("regressor_c2_h3_lr001_s2.keras")

"""#### Stride 3"""

regression_input_ = keras.layers.Input(shape=(X_train.shape[1], X_train.shape[2], 1))
regression_conv1 = keras.layers.Conv2D(32, (2,1), activation="relu", padding="same")(regression_input_)
regression_conv2 = keras.layers.Conv2D(32, (1,2), activation="relu", padding="same")(regression_conv1)
regression_pool1 = keras.layers.MaxPooling2D((2,2))(regression_conv2)
regression_dropout1 = keras.layers.Dropout(0.25)(regression_pool1)
regression_conv3 = keras.layers.Conv2D(64, (2,1), activation="relu", padding="same")(regression_dropout1)
regression_conv4 = keras.layers.Conv2D(64, (1,2), activation="relu", padding="same")(regression_conv3)
regression_pool2 = keras.layers.MaxPooling2D((2,2))(regression_conv4)
regression_dropout2 = keras.layers.Dropout(0.25)(regression_pool2)
regression_flatten = keras.layers.Flatten()(regression_dropout2)

regression_dense1 = keras.layers.Dense(256, activation="relu")(regression_flatten)
regression_dropout3 = keras.layers.Dropout(0.25)(regression_dense1)
regression_dense2 = keras.layers.Dense(256, activation="relu")(regression_dropout3)
regression_dropout4 = keras.layers.Dropout(0.25)(regression_dense2)
regression_dense3 = keras.layers.Dense(256, activation="relu")(regression_dropout4)
regression_dropout5 = keras.layers.Dropout(0.25)(regression_dense3)
regression_out = keras.layers.Dense(1, activation="relu")(regression_dropout5)

regression_model = keras.Model(inputs=[regression_input_], outputs=[regression_out])

tensorboard_cb = keras.callbacks.TensorBoard(log_root())
regression_model.compile(loss="mse", optimizer=keras.optimizers.SGD(),
                         metrics=["mean_absolute_error"])
regression_model.summary()

histories.append(regression_model.fit(X_train, y_train_regression, epochs=150, validation_data=(X_valid, y_valid_regression), callbacks=[tensorboard_cb]))
regressor_models.append(regression_model)

regression_model.save("regressor_c2_h3_lr001_s3.keras")

"""#### Regressor Results"""

plt.figure(figsize=(12,4))

plt.subplot(1,2,1)
for i in range(-3,0):
    plt.plot(histories[i].history["loss"])
plt.ylabel('loss')
plt.xlabel('epoch')
plt.title('Model Training Loss')
plt.legend(["Stride 1", "Stride 2", "Stride 3"], loc='upper center', bbox_to_anchor=(1.2, 1))

plt.subplot(1,2,2)
for i in range(-3,0):
    plt.plot(histories[i].history["val_loss"])
plt.ylabel('validation loss')
plt.xlabel('epoch')
plt.title('Model Validation Loss')
plt.legend(["Stride 1", "Stride 2", "Stride 3"], loc='upper center', bbox_to_anchor=(1.2, 1))
plt.subplots_adjust(wspace=0.55)

plt.figure(figsize=(12,4))

plt.subplot(1,2,1)
for i in range(-3,0):
    plt.plot(histories[i].history["mean_absolute_error"])
plt.ylabel('mean absolute error')
plt.xlabel('epoch')
plt.title('Model Training Mean Absolute Error')
plt.legend(["Stride 1", "Stride 2", "Stride 3"], loc='upper center', bbox_to_anchor=(1.2, 1))

plt.subplot(1,2,2)
for i in range(-3,0):
    plt.plot(histories[i].history["val_mean_absolute_error"][:10])
plt.ylabel('validation mean absolute error')
plt.xlabel('epoch')
plt.title('Model Validation Mean Absolute Error')
plt.legend(["Stride 1", "Stride 2", "Stride 3"], loc='upper center', bbox_to_anchor=(1.2, 1))
plt.subplots_adjust(wspace=0.55)

for i in range(nb_regressors):
    regression_model = regressor_models[i]
    regression_mean_common_sense_error = np.mean(common_sense_error(y_test_regression, regression_model.predict_on_batch(X_test)))
    name = model_names[i+nb_classifiers].split("_")
    print(f'The mean common sense error of the regression model with stride {i+1} is {regression_mean_common_sense_error // 1} hours and {(regression_mean_common_sense_error % 1) * 60} minutes.')

"""### Multi-Head"""

keras.utils.set_random_seed(seed)

"""#### Hour Classification and Minute regression (HC_MR)"""

hc_mr_input_ = keras.layers.Input(shape=(X_train.shape[1], X_train.shape[2], 1))
hc_mr_conv1 = keras.layers.Conv2D(32, (3,3), activation="relu", padding="same")(hc_mr_input_)
hc_mr_conv2 = keras.layers.Conv2D(32, (3,3), activation="relu", padding="same")(hc_mr_conv1)
hc_mr_pool1 = keras.layers.MaxPooling2D((2,2))(hc_mr_conv2)
hc_mr_dropout1 = keras.layers.Dropout(0.25)(hc_mr_pool1)
hc_mr_conv3 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same")(hc_mr_dropout1)
hc_mr_conv4 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same")(hc_mr_conv3)
hc_mr_pool2 = keras.layers.MaxPooling2D((2,2))(hc_mr_conv4)
hc_mr_dropout2 = keras.layers.Dropout(0.25)(hc_mr_pool2)
hc_mr_flatten = keras.layers.Flatten()(hc_mr_dropout2)

hc_mr_dense1 = keras.layers.Dense(256, activation="relu")(hc_mr_flatten)
hc_mr_dropout3 = keras.layers.Dropout(0.25)(hc_mr_dense1)
hc_mr_dense2 = keras.layers.Dense(256, activation="relu")(hc_mr_dropout3)
hc_mr_dropout4 = keras.layers.Dropout(0.25)(hc_mr_dense2)
hc_mr_dense3 = keras.layers.Dense(256, activation="relu")(hc_mr_dropout3)
hc_mr_dropout5 = keras.layers.Dropout(0.25)(hc_mr_dense3)
hc_mr_out_1 = keras.layers.Dense(12, activation="softmax")(hc_mr_dropout4)
hc_mr_out_2 = keras.layers.Dense(1, activation="relu")(hc_mr_dropout5)

hc_mr_model = keras.Model(inputs=[hc_mr_input_], outputs=[hc_mr_out_1, hc_mr_out_2])

tensorboard_cb = keras.callbacks.TensorBoard(log_root())
hc_mr_model.compile(loss=[keras.losses.SparseCategoricalCrossentropy(), "mse"], loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(),
                         metrics=["accuracy", "mean_absolute_error"])
hc_mr_model.summary()

histories.append(hc_mr_model.fit(X_train, [y_train[:,0], y_train[:,1]], epochs=150, validation_data=(X_valid, [y_valid[:,0], y_valid[:,1]]), callbacks=[tensorboard_cb]))

hc_mr_model.save("hc_mr.keras")

"""#### Hour Classification and Minute classification (HC_MC)"""

hc_mc_input_ = keras.layers.Input(shape=(X_train.shape[1], X_train.shape[2], 1))
hc_mc_conv1 = keras.layers.Conv2D(32, (3,3), activation="relu", padding="same")(hc_mc_input_)
hc_mc_conv2 = keras.layers.Conv2D(32, (3,3), activation="relu", padding="same")(hc_mc_conv1)
hc_mc_pool1 = keras.layers.MaxPooling2D((2,2))(hc_mc_conv2)
hc_mc_dropout1 = keras.layers.Dropout(0.25)(hc_mc_pool1)
hc_mc_conv3 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same")(hc_mc_dropout1)
hc_mc_conv4 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same")(hc_mc_conv3)
hc_mc_pool2 = keras.layers.MaxPooling2D((2,2))(hc_mc_conv4)
hc_mc_dropout2 = keras.layers.Dropout(0.25)(hc_mc_pool2)
hc_mc_flatten = keras.layers.Flatten()(hc_mc_dropout2)

hc_mc_dense1 = keras.layers.Dense(256, activation="relu")(hc_mc_flatten)
hc_mc_dropout3 = keras.layers.Dropout(0.25)(hc_mc_dense1)
hc_mc_dense2 = keras.layers.Dense(256, activation="relu")(hc_mc_dropout3)
hc_mc_dropout4 = keras.layers.Dropout(0.25)(hc_mc_dense2)
hc_mc_dense3 = keras.layers.Dense(256, activation="relu")(hc_mc_dropout3)
hc_mc_dropout5 = keras.layers.Dropout(0.25)(hc_mc_dense3)
hc_mc_out_1 = keras.layers.Dense(12, activation="softmax")(hc_mc_dropout4)
hc_mc_out_2 = keras.layers.Dense(60, activation="softmax")(hc_mc_dropout5)

hc_mc_model = keras.Model(inputs=[hc_mc_input_], outputs=[hc_mc_out_1, hc_mc_out_2])

tensorboard_cb = keras.callbacks.TensorBoard(log_root())
hc_mc_model.compile(loss=[keras.losses.SparseCategoricalCrossentropy(), keras.losses.SparseCategoricalCrossentropy()], loss_weights=[0.65, 0.35], optimizer=keras.optimizers.SGD(),
                         metrics=["accuracy", "accuracy"])
hc_mc_model.summary()

histories.append(hc_mc_model.fit(X_train, [y_train[:,0], y_train[:,1]], epochs=150, validation_data=(X_valid, [y_valid[:,0], y_valid[:,1]]), callbacks=[tensorboard_cb]))

hc_mc_model.save("hc_mc.keras")

"""#### Hour regression and Minute regression (HR_MR)"""

hr_mr_input_ = keras.layers.Input(shape=(X_train.shape[1], X_train.shape[2], 1))
hr_mr_conv1 = keras.layers.Conv2D(32, (3,3), activation="relu", padding="same")(hr_mr_input_)
hr_mr_conv2 = keras.layers.Conv2D(32, (3,3), activation="relu", padding="same")(hr_mr_conv1)
hr_mr_pool1 = keras.layers.MaxPooling2D((2,2))(hr_mr_conv2)
hr_mr_dropout1 = keras.layers.Dropout(0.25)(hr_mr_pool1)
hr_mr_conv3 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same")(hr_mr_dropout1)
hr_mr_conv4 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same")(hr_mr_conv3)
hr_mr_pool2 = keras.layers.MaxPooling2D((2,2))(hr_mr_conv4)
hr_mr_dropout2 = keras.layers.Dropout(0.25)(hr_mr_pool2)
hr_mr_flatten = keras.layers.Flatten()(hr_mr_dropout2)

hr_mr_dense1 = keras.layers.Dense(256, activation="relu")(hr_mr_flatten)
hr_mr_dropout3 = keras.layers.Dropout(0.25)(hr_mr_dense1)
hr_mr_dense2 = keras.layers.Dense(256, activation="relu")(hr_mr_dropout3)
hr_mr_dropout4 = keras.layers.Dropout(0.25)(hr_mr_dense2)
hr_mr_dense3 = keras.layers.Dense(256, activation="relu")(hr_mr_dropout3)
hr_mr_dropout5 = keras.layers.Dropout(0.25)(hr_mr_dense3)
hr_mr_out_1 = keras.layers.Dense(1, activation="relu")(hr_mr_dropout4)
hr_mr_out_2 = keras.layers.Dense(1, activation="relu")(hr_mr_dropout5)

hr_mr_model = keras.Model(inputs=[hr_mr_input_], outputs=[hr_mr_out_1, hr_mr_out_2])

tensorboard_cb = keras.callbacks.TensorBoard(log_root())
hr_mr_model.compile(loss=["mse", "mse"], loss_weights=[0.65, 0.35], optimizer=keras.optimizers.SGD(),
                         metrics=["mean_absolute_error", "mean_absolute_error"])
hr_mr_model.summary()

histories.append(hr_mr_model.fit(X_train, [y_train[:,0], y_train[:,1]], epochs=150, validation_data=(X_valid, [y_valid[:,0], y_valid[:,1]]), callbacks=[tensorboard_cb]))

hr_mr_model.save("hr_mr.keras")

"""#### Hour regression and Minute classification (HR_MC)"""

hr_mc_input_ = keras.layers.Input(shape=(X_train.shape[1], X_train.shape[2], 1))
hr_mc_conv1 = keras.layers.Conv2D(32, (3,3), activation="relu", padding="same")(hr_mc_input_)
hr_mc_conv2 = keras.layers.Conv2D(32, (3,3), activation="relu", padding="same")(hr_mc_conv1)
hr_mc_pool1 = keras.layers.MaxPooling2D((2,2))(hr_mc_conv2)
hr_mc_dropout1 = keras.layers.Dropout(0.25)(hr_mc_pool1)
hr_mc_conv3 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same")(hr_mc_dropout1)
hr_mc_conv4 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same")(hr_mc_conv3)
hr_mc_pool2 = keras.layers.MaxPooling2D((2,2))(hr_mc_conv4)
hr_mc_dropout2 = keras.layers.Dropout(0.25)(hr_mc_pool2)
hr_mc_flatten = keras.layers.Flatten()(hr_mc_dropout2)

hr_mc_dense1 = keras.layers.Dense(256, activation="relu")(hr_mc_flatten)
hr_mc_dropout3 = keras.layers.Dropout(0.25)(hr_mc_dense1)
hr_mc_dense2 = keras.layers.Dense(256, activation="relu")(hr_mc_dropout3)
hr_mc_dropout4 = keras.layers.Dropout(0.25)(hr_mc_dense2)
hr_mc_dense3 = keras.layers.Dense(256, activation="relu")(hr_mc_dropout3)
hr_mc_dropout5 = keras.layers.Dropout(0.25)(hr_mc_dense3)
hr_mc_out_1 = keras.layers.Dense(1, activation="relu")(hr_mc_dropout4)
hr_mc_out_2 = keras.layers.Dense(60, activation="softmax")(hr_mc_dropout5)

hr_mc_model = keras.Model(inputs=[hr_mc_input_], outputs=[hr_mc_out_1, hr_mc_out_2])

tensorboard_cb = keras.callbacks.TensorBoard(log_root())
hr_mc_model.compile(loss=["mse", keras.losses.SparseCategoricalCrossentropy()], loss_weights=[0.5, 0.5], optimizer=keras.optimizers.SGD(),
                         metrics=["mean_absolute_error", "accuracy"])
hr_mc_model.summary()

histories.append(hr_mc_model.fit(X_train, [y_train[:,0], y_train[:,1]], epochs=150, validation_data=(X_valid, [y_valid[:,0], y_valid[:,1]]), callbacks=[tensorboard_cb]))

hr_mc_model.save("hr_mc.keras")

"""#### Multi-head Results"""

plt.figure(figsize=(12,4))

plt.subplot(1,2,1)
plt.plot(histories[nb_classifiers+nb_regressors].history["loss"])
plt.plot(histories[nb_classifiers+nb_regressors+1].history["loss"])
plt.plot(histories[nb_classifiers+nb_regressors+2].history["loss"])
plt.plot(histories[nb_classifiers+nb_regressors+3].history["loss"])
plt.ylabel('loss')
plt.xlabel('epoch')
plt.title('Model Training Loss')
plt.legend(["HC_MR", "HC_MC", "HR_MR", "HR_MC"], loc='upper center', bbox_to_anchor=(1.2, 1))

plt.subplot(1,2,2)
plt.plot(histories[nb_classifiers+nb_regressors].history["val_loss"])
plt.plot(histories[nb_classifiers+nb_regressors+1].history["val_loss"])
plt.plot(histories[nb_classifiers+nb_regressors+2].history["val_loss"])
plt.plot(histories[nb_classifiers+nb_regressors+3].history["val_loss"])
plt.ylabel('validation loss')
plt.xlabel('epoch')
plt.title('Model Validation Loss')
plt.legend(["HC_MR", "HC_MC", "HR_MR", "HR_MC"], loc='upper center', bbox_to_anchor=(1.2, 1))
plt.subplots_adjust(wspace=0.55)

hc_mr_outs = hc_mr_model.predict_on_batch(X_test)
hc_mc_outs = hc_mc_model.predict_on_batch(X_test)
hr_mr_outs = hr_mr_model.predict_on_batch(X_test)
hr_mc_outs = hr_mc_model.predict_on_batch(X_test)

hc_mr_scaled_outs = np.argmax(hc_mr_outs[0], axis=1) +  np.argmax(hc_mr_outs[1], axis=1) / 60
hc_mc_scaled_outs = np.argmax(hc_mc_outs[0], axis=1) +  np.argmax(hc_mc_outs[1], axis=1) / 60
hr_mr_scaled_outs = np.argmax(hr_mr_outs[0], axis=1) +  np.argmax(hr_mr_outs[1], axis=1) / 60
hr_mc_scaled_outs = np.argmax(hr_mc_outs[0], axis=1) +  np.argmax(hr_mc_outs[1], axis=1) / 60

hc_mr_outs_mean_common_sense_error = np.mean(common_sense_error(y_test_regression, hc_mr_scaled_outs))
hc_mc_outs_mean_common_sense_error = np.mean(common_sense_error(y_test_regression, hc_mc_scaled_outs))
hr_mr_outs_mean_common_sense_error = np.mean(common_sense_error(y_test_regression, hr_mr_scaled_outs))
hr_mc_outs_mean_common_sense_error = np.mean(common_sense_error(y_test_regression, hr_mc_scaled_outs))

print(f'The mean common sense error of the hour classification and minute regression model is {hc_mr_outs_mean_common_sense_error // 1} hours and {hc_mr_outs_mean_common_sense_error % 1 * 60} minutes.')
print(f'The mean common sense error of the hour classification and minute classification model is {hc_mc_outs_mean_common_sense_error // 1} hours and {hc_mc_outs_mean_common_sense_error % 1 * 60} minutes.')
print(f'The mean common sense error of the hour regression and minute regression model is {hr_mr_outs_mean_common_sense_error // 1} hours and {hr_mr_outs_mean_common_sense_error % 1 * 60} minutes.')
print(f'The mean common sense error of the hour regression and minute classification model is {hr_mc_outs_mean_common_sense_error // 1} hours and {hr_mc_outs_mean_common_sense_error % 1 * 60} minutes.')

"""### Label Tranformation"""

keras.utils.set_random_seed(seed)

"""#### Four-head Sine and cosine"""

y_test_h_cos = np.cos(y_test[:, 0] / 6 * np.pi)
y_test_h_sin = np.sin(y_test[:, 0] / 6 * np.pi)
y_test_m_cos = np.cos(y_test[:, 1] / 30 * np.pi)
y_test_m_sin = np.sin(y_test[:, 1] / 30 * np.pi)

y_valid_h_cos = np.cos(y_valid[:, 0] / 6 * np.pi)
y_valid_h_sin = np.sin(y_valid[:, 0] / 6 * np.pi)
y_valid_m_cos = np.cos(y_valid[:, 1] / 30 * np.pi)
y_valid_m_sin = np.sin(y_valid[:, 1] / 30 * np.pi)

y_train_h_cos = np.cos(y_train[:, 0] / 6 * np.pi)
y_train_h_sin = np.sin(y_train[:, 0] / 6 * np.pi)
y_train_m_cos = np.cos(y_train[:, 1] / 30 * np.pi)
y_train_m_sin = np.sin(y_train[:, 1] / 30 * np.pi) # adapt the labels to match the output of our model

sincos_input_ = keras.layers.Input(shape=(X_train.shape[1], X_train.shape[2], 1))
sincos_conv1 = keras.layers.Conv2D(32, (3,3), activation="relu", padding="same")(sincos_input_)
sincos_conv2 = keras.layers.Conv2D(32, (3,3), activation="relu", padding="same")(sincos_conv1)
sincos_pool1 = keras.layers.MaxPooling2D((2,2))(sincos_conv2)
sincos_dropout1 = keras.layers.Dropout(0.25)(sincos_pool1)
sincos_conv3 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same")(sincos_dropout1)
sincos_conv4 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same")(sincos_conv3)
sincos_pool2 = keras.layers.MaxPooling2D((2,2))(sincos_conv4)
sincos_dropout2 = keras.layers.Dropout(0.25)(sincos_pool2)
sincos_flatten = keras.layers.Flatten()(sincos_dropout2)

sincos_dense1 = keras.layers.Dense(256, activation="relu")(sincos_flatten)
sincos_dropout12 = keras.layers.Dropout(0.25)(sincos_dense1)
sincos_dense10 = keras.layers.Dense(256, activation="relu")(sincos_dropout12)
sincos_dropout3 = keras.layers.Dropout(0.25)(sincos_dense10)
sincos_dense2 = keras.layers.Dense(128, activation="relu")(sincos_dropout3)
sincos_dropout4 = keras.layers.Dropout(0.25)(sincos_dense2)
sincos_dense3 = keras.layers.Dense(64, activation="relu")(sincos_dropout4)
sincos_dropout5 = keras.layers.Dropout(0.25)(sincos_dense3)
sincos_dense4 = keras.layers.Dense(128, activation="relu")(sincos_dropout3)
sincos_dropout6 = keras.layers.Dropout(0.25)(sincos_dense4)
sincos_dense5 = keras.layers.Dense(64, activation="relu")(sincos_dropout6)
sincos_dropout7 = keras.layers.Dropout(0.25)(sincos_dense5)
sincos_dense6 = keras.layers.Dense(128, activation="relu")(sincos_dropout3)
sincos_dropout8 = keras.layers.Dropout(0.25)(sincos_dense6)
sincos_dense7 = keras.layers.Dense(64, activation="relu")(sincos_dropout8)
sincos_dropout9 = keras.layers.Dropout(0.25)(sincos_dense7)
sincos_dense8 = keras.layers.Dense(128, activation="relu")(sincos_dropout3)
sincos_dropout10 = keras.layers.Dropout(0.25)(sincos_dense8)
sincos_dense9 = keras.layers.Dense(64, activation="relu")(sincos_dropout10)
sincos_dropout11 = keras.layers.Dropout(0.25)(sincos_dense9)
sincos_out_1 = keras.layers.Dense(1, activation="tanh")(sincos_dropout5)
sincos_out_2 = keras.layers.Dense(1, activation="tanh")(sincos_dropout7)
sincos_out_3 = keras.layers.Dense(1, activation="tanh")(sincos_dropout9)
sincos_out_4 = keras.layers.Dense(1, activation="tanh")(sincos_dropout11)

sincos_model = keras.Model(inputs=[sincos_input_], outputs=[sincos_out_1, sincos_out_2, sincos_out_3, sincos_out_4])

tensorboard_cb = keras.callbacks.TensorBoard(log_root())
sincos_model.compile(loss=[keras.losses.MeanAbsoluteError(), keras.losses.MeanAbsoluteError(), keras.losses.MeanAbsoluteError(), keras.losses.MeanAbsoluteError()],
                     loss_weights=[0.65, 0.65, 0.35, 0.35], optimizer=keras.optimizers.SGD(learning_rate=0.01),
                    metrics=["mean_absolute_error", "mean_absolute_error", "mean_absolute_error", "mean_absolute_error"])
sincos_model.summary()

histories.append(sincos_model.fit(X_train, [y_train_h_cos, y_train_h_sin, y_train_m_cos, y_train_m_sin], epochs=150, validation_data=(X_valid, [y_valid_h_cos, y_valid_h_sin, y_valid_m_cos, y_valid_m_sin]), callbacks=[tensorboard_cb]))

sincos_model.save("sincos.keras")

"""#### Two-head Sine and cosine"""

y_test_cos = np.cos(y_test_regression / 6 * np.pi)
y_test_sin = np.sin(y_test_regression / 6 * np.pi)

y_valid_cos = np.cos(y_valid_regression / 6 * np.pi)
y_valid_sin = np.sin(y_valid_regression / 6 * np.pi)

y_train_cos = np.cos(y_train_regression / 6 * np.pi)
y_train_sin = np.sin(y_train_regression / 6 * np.pi) # adapt the labels to match the output of our model

sincos_2h_input_ = keras.layers.Input(shape=(X_train.shape[1], X_train.shape[2], 1))
sincos_2h_conv1 = keras.layers.Conv2D(32, (3,3), activation="relu", padding="same")(sincos_2h_input_)
sincos_2h_conv2 = keras.layers.Conv2D(32, (3,3), activation="relu", padding="same")(sincos_2h_conv1)
sincos_2h_pool1 = keras.layers.MaxPooling2D((2,2))(sincos_2h_conv2)
sincos_2h_dropout1 = keras.layers.Dropout(0.25)(sincos_2h_pool1)
sincos_2h_conv3 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same")(sincos_2h_dropout1)
sincos_2h_conv4 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same")(sincos_2h_conv3)
sincos_2h_pool2 = keras.layers.MaxPooling2D((2,2))(sincos_2h_conv4)
sincos_2h_dropout2 = keras.layers.Dropout(0.25)(sincos_2h_pool2)
sincos_2h_flatten = keras.layers.Flatten()(sincos_2h_dropout2)

sincos_2h_dense1 = keras.layers.Dense(256, activation="relu")(sincos_2h_flatten)
sincos_2h_dropout3 = keras.layers.Dropout(0.25)(sincos_2h_dense1)
sincos_2h_dense2 = keras.layers.Dense(128, activation="relu")(sincos_2h_dropout3)
sincos_2h_dropout4 = keras.layers.Dropout(0.25)(sincos_2h_dense2)
sincos_2h_dense3 = keras.layers.Dense(64, activation="relu")(sincos_2h_dropout4)
sincos_2h_dropout5 = keras.layers.Dropout(0.25)(sincos_2h_dense3)
sincos_2h_dense4 = keras.layers.Dense(128, activation="relu")(sincos_2h_dropout3)
sincos_2h_dropout6 = keras.layers.Dropout(0.25)(sincos_2h_dense4)
sincos_2h_dense5 = keras.layers.Dense(64, activation="relu")(sincos_2h_dropout6)
sincos_2h_dropout7 = keras.layers.Dropout(0.25)(sincos_2h_dense5)
sincos_2h_out_1 = keras.layers.Dense(1, activation="tanh")(sincos_2h_dropout5)
sincos_2h_out_2 = keras.layers.Dense(1, activation="tanh")(sincos_2h_dropout7)

sincos_2h_model = keras.Model(inputs=[sincos_2h_input_], outputs=[sincos_2h_out_1, sincos_2h_out_2])

tensorboard_cb = keras.callbacks.TensorBoard(log_root())
sincos_2h_model.compile(loss=[keras.losses.MeanAbsoluteError(), keras.losses.MeanAbsoluteError()], optimizer=keras.optimizers.SGD(learning_rate=0.01),
                    metrics=["mean_absolute_error", "mean_absolute_error"])
sincos_2h_model.summary()

histories.append(sincos_2h_model.fit(X_train, [y_train_cos, y_train_sin], epochs=150, validation_data=(X_valid, [y_valid_cos, y_valid_sin]), callbacks=[tensorboard_cb]))

sincos_2h_model.save("sincos_2h_model.keras")

"""#### Label Transformation Results"""

plt.figure(figsize=(12,4))

plt.subplot(1,2,1)

plt.plot(histories[-1].history["loss"])
plt.plot(histories[-2].history["loss"])
plt.ylabel('loss')
plt.xlabel('epoch')
plt.title('Model Training Loss')
plt.legend(["2 heads", "4 heads"], loc='upper center', bbox_to_anchor=(1.2, 1))

plt.subplot(1,2,2)
plt.plot(histories[-1].history["val_loss"])
plt.plot(histories[-2].history["val_loss"])
plt.ylabel('validation loss')
plt.xlabel('epoch')
plt.title('Model Validation Loss')
plt.legend(["2 heads", "4 heads"], loc='upper center', bbox_to_anchor=(1.2, 1))
plt.subplots_adjust(wspace=0.55)

sincos_outs = np.transpose(np.squeeze(np.array(sincos_model.predict_on_batch(X_test))), (1, 0))
angle_arr = np.zeros((sincos_outs.shape[0], 2))
angle_arr[:,0] = np.arctan2(sincos_outs[:, 1], sincos_outs[:, 0]) / np.pi
angle_arr[:,0] = np.where(angle_arr[:,0] >= 0, angle_arr[:,0] * 6 // 1, (angle_arr[:,0] + 2) * 6 // 1)
angle_arr[:,1] = np.arctan2(sincos_outs[:, 3], sincos_outs[:, 2]) / np.pi
angle_arr[:,1] = np.where(angle_arr[:,1] >= 0, angle_arr[:,1] * 30, (angle_arr[:,0] + 2) * 30)
sincos_scaled_outs = angle_arr[:, 0] + angle_arr[:,1] / 60
sincos_mean_common_sense_error = np.mean(common_sense_error(y_test_regression, sincos_scaled_outs))
print(f'The mean common sense error of the four head label transformation model is {sincos_mean_common_sense_error // 1} hours and {sincos_mean_common_sense_error % 1 * 60} minutes.')

sincos_2h_outs = np.transpose(np.squeeze(np.array(sincos_2h_model.predict_on_batch(X_test))), (1, 0))
angle_arr = np.zeros((sincos_2h_outs.shape[0], 1))
angle_arr[:,0] = np.arctan2(sincos_2h_outs[:, 1], sincos_2h_outs[:, 0]) / np.pi
angle_arr[:,0] = np.where(angle_arr[:,0] >= 0, angle_arr[:,0] * 6, (angle_arr[:,0] + 2) * 6)
sincos_scaled_outs = angle_arr[:, 0]
sincos_mean_common_sense_error = np.mean(common_sense_error(y_test_regression, sincos_scaled_outs))
print(f'The mean common sense error of the two head label transformation model is {sincos_mean_common_sense_error // 1} hours and {sincos_mean_common_sense_error % 1 * 60} minutes.')

"""## 2.2

### Data Separation
"""

keras.utils.set_random_seed(seed+1)

X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2)

X_train = X_train.astype("float32")
X_valid = X_valid.astype("float32")
X_test = X_test.astype("float32")

X_train /= 255
X_valid /= 255
X_test /= 255

y_test_regression = y_test[:,0] + y_test[:, 1] / 60
y_train_regression = y_train[:,0] + y_train[:, 1] / 60

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

"""### Models

#### Model 1
"""

y_test_cos = np.cos(y_test_regression / 6 * np.pi)
y_test_sin = np.sin(y_test_regression / 6 * np.pi)

y_train_cos = np.cos(y_train_regression / 6 * np.pi)
y_train_sin = np.sin(y_train_regression / 6 * np.pi) # adapt the labels to match the output of our model

sincos_2h_input_ = keras.layers.Input(shape=(X_train.shape[1], X_train.shape[2], 1))
sincos_2h_conv1 = keras.layers.Conv2D(32, (3,3), activation="relu", padding="same")(sincos_2h_input_)
sincos_2h_conv2 = keras.layers.Conv2D(32, (3,3), activation="relu", padding="same")(sincos_2h_conv1)
sincos_2h_pool1 = keras.layers.MaxPooling2D((2,2))(sincos_2h_conv2)
sincos_2h_dropout1 = keras.layers.Dropout(0.25)(sincos_2h_pool1)
sincos_2h_conv3 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same")(sincos_2h_dropout1)
sincos_2h_conv4 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same")(sincos_2h_conv3)
sincos_2h_pool2 = keras.layers.MaxPooling2D((2,2))(sincos_2h_conv4)
sincos_2h_dropout2 = keras.layers.Dropout(0.25)(sincos_2h_pool2)
sincos_2h_flatten = keras.layers.Flatten()(sincos_2h_dropout2)

sincos_2h_dense1 = keras.layers.Dense(256, activation="relu")(sincos_2h_flatten)
sincos_2h_dropout3 = keras.layers.Dropout(0.25)(sincos_2h_dense1)
sincos_2h_dense2 = keras.layers.Dense(128, activation="relu")(sincos_2h_dropout3)
sincos_2h_dropout4 = keras.layers.Dropout(0.25)(sincos_2h_dense2)
sincos_2h_dense3 = keras.layers.Dense(64, activation="relu")(sincos_2h_dropout4)
sincos_2h_dropout5 = keras.layers.Dropout(0.25)(sincos_2h_dense3)
sincos_2h_dense4 = keras.layers.Dense(128, activation="relu")(sincos_2h_dropout3)
sincos_2h_dropout6 = keras.layers.Dropout(0.25)(sincos_2h_dense4)
sincos_2h_dense5 = keras.layers.Dense(64, activation="relu")(sincos_2h_dropout6)
sincos_2h_dropout7 = keras.layers.Dropout(0.25)(sincos_2h_dense5)
sincos_2h_out_1 = keras.layers.Dense(1, activation="tanh")(sincos_2h_dropout5)
sincos_2h_out_2 = keras.layers.Dense(1, activation="tanh")(sincos_2h_dropout7)

model_1 = keras.Model(inputs=[sincos_2h_input_], outputs=[sincos_2h_out_1, sincos_2h_out_2])

tensorboard_cb = keras.callbacks.TensorBoard(log_root())
model_1.compile(loss=[keras.losses.MeanAbsoluteError(), keras.losses.MeanAbsoluteError()], optimizer=keras.optimizers.SGD(learning_rate=0.01),
                    metrics=["mean_absolute_error", "mean_absolute_error"])
model_1.summary()

m1_history = model_1.fit(X_train, [y_train_cos, y_train_sin], epochs=300, callbacks=[tensorboard_cb])

model_1.save("final_model_1.keras")

"""#### Model 2"""

sincos_2h_input_ = keras.layers.Input(shape=(X_train.shape[1], X_train.shape[2], 1))
sincos_2h_conv1 = keras.layers.Conv2D(32, (6,6), activation="relu", padding="same")(sincos_2h_input_)
sincos_2h_conv2 = keras.layers.Conv2D(32, (6,6), activation="relu", padding="same")(sincos_2h_conv1)
sincos_2h_pool1 = keras.layers.MaxPooling2D((2,2))(sincos_2h_conv2)
sincos_2h_dropout1 = keras.layers.Dropout(0.25)(sincos_2h_pool1)
sincos_2h_conv3 = keras.layers.Conv2D(64, (6,6), activation="relu", padding="same")(sincos_2h_dropout1)
sincos_2h_conv4 = keras.layers.Conv2D(64, (6,6), activation="relu", padding="same")(sincos_2h_conv3)
sincos_2h_pool2 = keras.layers.MaxPooling2D((2,2))(sincos_2h_conv4)
sincos_2h_dropout2 = keras.layers.Dropout(0.25)(sincos_2h_pool2)
sincos_2h_flatten = keras.layers.Flatten()(sincos_2h_dropout2)

sincos_2h_dense1 = keras.layers.Dense(256, activation="relu")(sincos_2h_flatten)
sincos_2h_dropout3 = keras.layers.Dropout(0.25)(sincos_2h_dense1)
sincos_2h_dense2 = keras.layers.Dense(128, activation="relu")(sincos_2h_dropout3)
sincos_2h_dropout4 = keras.layers.Dropout(0.25)(sincos_2h_dense2)
sincos_2h_dense3 = keras.layers.Dense(64, activation="relu")(sincos_2h_dropout4)
sincos_2h_dropout5 = keras.layers.Dropout(0.25)(sincos_2h_dense3)
sincos_2h_dense4 = keras.layers.Dense(128, activation="relu")(sincos_2h_dropout3)
sincos_2h_dropout6 = keras.layers.Dropout(0.25)(sincos_2h_dense4)
sincos_2h_dense5 = keras.layers.Dense(64, activation="relu")(sincos_2h_dropout6)
sincos_2h_dropout7 = keras.layers.Dropout(0.25)(sincos_2h_dense5)
sincos_2h_out_1 = keras.layers.Dense(1, activation="tanh")(sincos_2h_dropout5)
sincos_2h_out_2 = keras.layers.Dense(1, activation="tanh")(sincos_2h_dropout7)

model_2 = keras.Model(inputs=[sincos_2h_input_], outputs=[sincos_2h_out_1, sincos_2h_out_2])

tensorboard_cb = keras.callbacks.TensorBoard(log_root())
model_2.compile(loss=[keras.losses.MeanAbsoluteError(), keras.losses.MeanAbsoluteError()], optimizer=keras.optimizers.SGD(learning_rate=0.01),
                    metrics=["mean_absolute_error", "mean_absolute_error"])
model_2.summary()

m2_history = model_2.fit(X_train, [y_train_cos, y_train_sin], epochs=300, callbacks=[tensorboard_cb])

model_2.save("final_model_2.keras")

"""#### Model 3"""

sincos_2h_input_ = keras.layers.Input(shape=(X_train.shape[1], X_train.shape[2], 1))
sincos_2h_avgpool = keras.layers.AveragePooling2D((2,2))(sincos_2h_input_)
sincos_2h_conv1 = keras.layers.Conv2D(32, (3,3), activation="relu", padding="same")(sincos_2h_avgpool)
sincos_2h_conv2 = keras.layers.Conv2D(32, (3,3), activation="relu", padding="same")(sincos_2h_conv1)
sincos_2h_pool1 = keras.layers.MaxPooling2D((2,2))(sincos_2h_conv2)
sincos_2h_dropout1 = keras.layers.Dropout(0.25)(sincos_2h_pool1)
sincos_2h_conv3 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same")(sincos_2h_dropout1)
sincos_2h_conv4 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same")(sincos_2h_conv3)
sincos_2h_pool2 = keras.layers.MaxPooling2D((2,2))(sincos_2h_conv4)
sincos_2h_dropout2 = keras.layers.Dropout(0.25)(sincos_2h_pool2)
sincos_2h_flatten = keras.layers.Flatten()(sincos_2h_dropout2)

sincos_2h_dense1 = keras.layers.Dense(256, activation="relu")(sincos_2h_flatten)
sincos_2h_dropout3 = keras.layers.Dropout(0.25)(sincos_2h_dense1)
sincos_2h_dense2 = keras.layers.Dense(128, activation="relu")(sincos_2h_dropout3)
sincos_2h_dropout4 = keras.layers.Dropout(0.25)(sincos_2h_dense2)
sincos_2h_dense3 = keras.layers.Dense(64, activation="relu")(sincos_2h_dropout4)
sincos_2h_dropout5 = keras.layers.Dropout(0.25)(sincos_2h_dense3)
sincos_2h_dense4 = keras.layers.Dense(128, activation="relu")(sincos_2h_dropout3)
sincos_2h_dropout6 = keras.layers.Dropout(0.25)(sincos_2h_dense4)
sincos_2h_dense5 = keras.layers.Dense(64, activation="relu")(sincos_2h_dropout6)
sincos_2h_dropout7 = keras.layers.Dropout(0.25)(sincos_2h_dense5)
sincos_2h_out_1 = keras.layers.Dense(1, activation="tanh")(sincos_2h_dropout5)
sincos_2h_out_2 = keras.layers.Dense(1, activation="tanh")(sincos_2h_dropout7)

model_3 = keras.Model(inputs=[sincos_2h_input_], outputs=[sincos_2h_out_1, sincos_2h_out_2])

tensorboard_cb = keras.callbacks.TensorBoard(log_root())
model_3.compile(loss=[keras.losses.MeanAbsoluteError(), keras.losses.MeanAbsoluteError()], optimizer=keras.optimizers.SGD(learning_rate=0.01),
                    metrics=["mean_absolute_error", "mean_absolute_error"])
model_3.summary()

m3_history = model_3.fit(X_train, [y_train_cos, y_train_sin], epochs=300, callbacks=[tensorboard_cb])

model_3.save("final_model_3.keras")

"""#### Model 4"""

hc_mc_input_ = keras.layers.Input(shape=(X_train.shape[1], X_train.shape[2], 1))
hc_mc_conv1 = keras.layers.Conv2D(32, (3,3), activation="relu", padding="same")(hc_mc_input_)
hc_mc_conv2 = keras.layers.Conv2D(32, (3,3), activation="relu", padding="same")(hc_mc_conv1)
hc_mc_pool1 = keras.layers.MaxPooling2D((2,2))(hc_mc_conv2)
hc_mc_dropout1 = keras.layers.Dropout(0.25)(hc_mc_pool1)
hc_mc_conv3 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same")(hc_mc_dropout1)
hc_mc_conv4 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same")(hc_mc_conv3)
hc_mc_pool2 = keras.layers.MaxPooling2D((2,2))(hc_mc_conv4)
hc_mc_dropout2 = keras.layers.Dropout(0.25)(hc_mc_pool2)
hc_mc_flatten = keras.layers.Flatten()(hc_mc_dropout2)

hc_mc_dense1 = keras.layers.Dense(256, activation="relu")(hc_mc_flatten)
hc_mc_dropout3 = keras.layers.Dropout(0.25)(hc_mc_dense1)
hc_mc_dense2 = keras.layers.Dense(256, activation="relu")(hc_mc_dropout3)
hc_mc_dropout4 = keras.layers.Dropout(0.25)(hc_mc_dense2)
hc_mc_dense3 = keras.layers.Dense(256, activation="relu")(hc_mc_dropout3)
hc_mc_dropout5 = keras.layers.Dropout(0.25)(hc_mc_dense3)
hc_mc_dense4 = keras.layers.Dense(128, activation="relu")(hc_mc_dropout4)
hc_mc_dropout6 = keras.layers.Dropout(0.25)(hc_mc_dense4)
hc_mc_dense5 = keras.layers.Dense(128, activation="relu")(hc_mc_dropout5)
hc_mc_dropout7 = keras.layers.Dropout(0.25)(hc_mc_dense5)
hc_mc_out_1 = keras.layers.Dense(12, activation="softmax")(hc_mc_dropout6)
hc_mc_out_2 = keras.layers.Dense(60, activation="softmax")(hc_mc_dropout7)

model_4 = keras.Model(inputs=[hc_mc_input_], outputs=[hc_mc_out_1, hc_mc_out_2])

tensorboard_cb = keras.callbacks.TensorBoard(log_root())
model_4.compile(loss=[keras.losses.SparseCategoricalCrossentropy(), keras.losses.SparseCategoricalCrossentropy()], loss_weights=[0.65, 0.35], optimizer=keras.optimizers.SGD(),
                         metrics=["accuracy", "accuracy"])
model_4.summary()

m4_history = model_4.fit(X_train, [y_train[:,0], y_train[:,1]], epochs=300, callbacks=[tensorboard_cb])

model_4.save("final_model_4.keras")

"""#### Model 5"""

hc_mc_input_ = keras.layers.Input(shape=(X_train.shape[1], X_train.shape[2], 1))
hc_mc_conv1 = keras.layers.Conv2D(32, (3,3), activation="relu", padding="same")(hc_mc_input_)
hc_mc_conv2 = keras.layers.Conv2D(32, (3,3), activation="relu", padding="same")(hc_mc_conv1)
hc_mc_pool1 = keras.layers.MaxPooling2D((2,2))(hc_mc_conv2)
hc_mc_dropout1 = keras.layers.Dropout(0.25)(hc_mc_pool1)
hc_mc_conv3 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same")(hc_mc_dropout1)
hc_mc_conv4 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same")(hc_mc_conv3)
hc_mc_pool2 = keras.layers.MaxPooling2D((2,2))(hc_mc_conv4)
hc_mc_dropout2 = keras.layers.Dropout(0.25)(hc_mc_pool2)
hc_mc_conv5 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same")(hc_mc_dropout2)
hc_mc_conv6 = keras.layers.Conv2D(64, (3,3), activation="relu", padding="same")(hc_mc_conv5)
hc_mc_pool3 = keras.layers.MaxPooling2D((2,2))(hc_mc_conv6)
hc_mc_dropout3 = keras.layers.Dropout(0.25)(hc_mc_pool3)
hc_mc_flatten = keras.layers.Flatten()(hc_mc_dropout3)

hc_mc_dense1 = keras.layers.Dense(256, activation="relu")(hc_mc_flatten)
hc_mc_dropout3 = keras.layers.Dropout(0.25)(hc_mc_dense1)
hc_mc_dense2 = keras.layers.Dense(256, activation="relu")(hc_mc_dropout3)
hc_mc_dropout4 = keras.layers.Dropout(0.25)(hc_mc_dense2)
hc_mc_dense3 = keras.layers.Dense(256, activation="relu")(hc_mc_dropout3)
hc_mc_dropout5 = keras.layers.Dropout(0.25)(hc_mc_dense3)
hc_mc_out_1 = keras.layers.Dense(12, activation="softmax")(hc_mc_dropout4)
hc_mc_out_2 = keras.layers.Dense(60, activation="softmax")(hc_mc_dropout5)

model_5 = keras.Model(inputs=[hc_mc_input_], outputs=[hc_mc_out_1, hc_mc_out_2])

tensorboard_cb = keras.callbacks.TensorBoard(log_root())
model_5.compile(loss=[keras.losses.SparseCategoricalCrossentropy(), keras.losses.SparseCategoricalCrossentropy()], loss_weights=[0.65, 0.35], optimizer=keras.optimizers.SGD(),
                         metrics=["accuracy", "accuracy"])
model_5.summary()

m5_history = model_5.fit(X_train, [y_train[:,0], y_train[:,1]], epochs=300, callbacks=[tensorboard_cb])

model_5.save("final_model_5.keras")

"""### Final Results"""

plt.figure(figsize=(5,4))

plt.plot(m1_history.history["loss"])
plt.plot(m2_history.history["loss"])
plt.plot(m3_history.history["loss"])
plt.plot(m4_history.history["loss"])
plt.plot(m5_history.history["loss"])
plt.ylabel('loss')
plt.xlabel('epoch')
plt.title('Model Training Loss')
plt.legend(["Model 1", "Model 2", "Model 3", "Model 4", "Model 5"], loc='upper center', bbox_to_anchor=(1.2, 1))

plt.subplots_adjust(wspace=0.55)

sincos_2h_outs = np.transpose(np.squeeze(np.array(model_1.predict(X_test))), (1, 0))
angle_arr = np.zeros((sincos_2h_outs.shape[0], 1))
angle_arr[:,0] = np.arctan2(sincos_2h_outs[:, 1], sincos_2h_outs[:, 0]) / np.pi
angle_arr[:,0] = np.where(angle_arr[:,0] >= 0, angle_arr[:,0] * 6, (angle_arr[:,0] + 2) * 6)
sincos_scaled_outs = angle_arr[:, 0]
sincos_mean_common_sense_error = np.mean(common_sense_error(y_test_regression, sincos_scaled_outs))
print(f'The mean common sense error of model 1 is {sincos_mean_common_sense_error // 1} hours and {sincos_mean_common_sense_error % 1 * 60} minutes.')

sincos_2h_outs = np.transpose(np.squeeze(np.array(model_2.predict(X_test))), (1, 0))
angle_arr = np.zeros((sincos_2h_outs.shape[0], 1))
angle_arr[:,0] = np.arctan2(sincos_2h_outs[:, 1], sincos_2h_outs[:, 0]) / np.pi
angle_arr[:,0] = np.where(angle_arr[:,0] >= 0, angle_arr[:,0] * 6, (angle_arr[:,0] + 2) * 6)
sincos_scaled_outs = angle_arr[:, 0]
sincos_mean_common_sense_error = np.mean(common_sense_error(y_test_regression, sincos_scaled_outs))
print(f'The mean common sense error of model 2 is {sincos_mean_common_sense_error // 1} hours and {sincos_mean_common_sense_error % 1 * 60} minutes.')

sincos_2h_outs = np.transpose(np.squeeze(np.array(model_3.predict(X_test))), (1, 0))
angle_arr = np.zeros((sincos_2h_outs.shape[0], 1))
angle_arr[:,0] = np.arctan2(sincos_2h_outs[:, 1], sincos_2h_outs[:, 0]) / np.pi
angle_arr[:,0] = np.where(angle_arr[:,0] >= 0, angle_arr[:,0] * 6, (angle_arr[:,0] + 2) * 6)
sincos_scaled_outs = angle_arr[:, 0]
sincos_mean_common_sense_error = np.mean(common_sense_error(y_test_regression, sincos_scaled_outs))
print(f'The mean common sense error of model 3 is {sincos_mean_common_sense_error // 1} hours and {sincos_mean_common_sense_error % 1 * 60} minutes.')

hc_mc_outs = model_4.predict(X_test)

hc_mc_scaled_outs = np.argmax(hc_mc_outs[0], axis=1) +  np.argmax(hc_mc_outs[1], axis=1) / 60

hc_mc_outs_mean_common_sense_error = np.mean(common_sense_error(y_test_regression, hc_mc_scaled_outs))

print(f'The mean common sense error of model 4 is {hc_mc_outs_mean_common_sense_error // 1} hours and {hc_mc_outs_mean_common_sense_error % 1 * 60} minutes.')

hc_mc_outs = model_5.predict(X_test)

hc_mc_scaled_outs = np.argmax(hc_mc_outs[0], axis=1) +  np.argmax(hc_mc_outs[1], axis=1) / 60

hc_mc_outs_mean_common_sense_error = np.mean(common_sense_error(y_test_regression, hc_mc_scaled_outs))

print(f'The mean common sense error of model 5 is {hc_mc_outs_mean_common_sense_error // 1} hours and {hc_mc_outs_mean_common_sense_error % 1 * 60} minutes.')